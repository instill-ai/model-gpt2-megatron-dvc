---
Task: TextGeneration
Tags:
  - TextGeneration
  - GPT-2
---

# Model-GPT2-Megatron-dvc

ðŸ”¥ðŸ”¥ðŸ”¥ Deploy [GPT-2](https://huggingface.co/nvidia/megatron-gpt2-345m) Megatron-LM model on [VDP](https://github.com/instill-ai/vdp). It is trained on text sourced from Wikipedia, RealNews, OpenWebText, and CC-Stories and contains 345 million parameters.

This repo contains GPT-2 model in [FasterTransformer](https://github.com/NVIDIA/FasterTransformer) format manged by [DVC](https://dvc.org/).